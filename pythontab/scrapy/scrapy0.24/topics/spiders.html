
<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->

<!-- Mirrored from docs.pythontab.com/scrapy/scrapy0.24/topics/spiders.html by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 04 Oct 2022 03:51:21 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Spiders &mdash; Scrapy 中文手册 0.25 文档</title>
  
  
  
    
  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  
  
   
  <script src="../_static/js/modernizr.min.js"></script>
</head>
<body class="wy-body-for-nav" role="document">
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index-2.html" class="icon icon-home"> Scrapy 中文手册
          

          
          </a>

          
            
            
              <div class="version">
                0.25
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="https://docs.pythontab.com/scrapy/scrapy0.24/search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/overview.html">初窥Scrapy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/install.html">安装指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/tutorial.html">Scrapy入门教程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/examples.html">例子</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="commands.html">命令行工具(Command line tools)</a></li>
<li class="toctree-l1"><a class="reference internal" href="items.html">Items</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Spiders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#spider">Spider参数</a></li>
<li class="toctree-l2"><a class="reference internal" href="#topics-spiders-ref">内置Spider参考手册</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id2">Spider</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id5">Spider样例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#crawlspider">CrawlSpider</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#crawling-rules">爬取规则(Crawling rules)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id6">CrawlSpider样例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#xmlfeedspider">XMLFeedSpider</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id7">XMLFeedSpider例子</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#csvfeedspider">CSVFeedSpider</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id8">CSVFeedSpider例子</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#sitemapspider">SitemapSpider</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id9">SitemapSpider样例</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="selectors.html">选择器(Selectors)</a></li>
<li class="toctree-l1"><a class="reference internal" href="loaders.html">Item Loaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="shell.html">Scrapy终端(Scrapy shell)</a></li>
<li class="toctree-l1"><a class="reference internal" href="item-pipeline.html">Item Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="feed-exports.html">Feed exports</a></li>
<li class="toctree-l1"><a class="reference internal" href="link-extractors.html">Link Extractors</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="stats.html">数据收集(Stats Collection)</a></li>
<li class="toctree-l1"><a class="reference internal" href="email.html">发送email</a></li>
<li class="toctree-l1"><a class="reference internal" href="telnetconsole.html">Telnet终端(Telnet Console)</a></li>
<li class="toctree-l1"><a class="reference internal" href="webservice.html">Web Service</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">常见问题(FAQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="debug.html">调试(Debugging)Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="contracts.html">Spiders Contracts</a></li>
<li class="toctree-l1"><a class="reference internal" href="practices.html">实践经验(Common Practices)</a></li>
<li class="toctree-l1"><a class="reference internal" href="broad-crawls.html">通用爬虫(Broad Crawls)</a></li>
<li class="toctree-l1"><a class="reference internal" href="firefox.html">借助Firefox来爬取</a></li>
<li class="toctree-l1"><a class="reference internal" href="firebug.html">使用Firebug进行爬取</a></li>
<li class="toctree-l1"><a class="reference internal" href="leaks.html">调试内存溢出</a></li>
<li class="toctree-l1"><a class="reference internal" href="images.html">下载项目图片</a></li>
<li class="toctree-l1"><a class="reference internal" href="ubuntu.html">Ubuntu 软件包</a></li>
<li class="toctree-l1"><a class="reference internal" href="scrapyd.html">Scrapyd</a></li>
<li class="toctree-l1"><a class="reference internal" href="autothrottle.html">自动限速(AutoThrottle)扩展</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="jobs.html">Jobs: 暂停，恢复爬虫</a></li>
<li class="toctree-l1"><a class="reference internal" href="djangoitem.html">DjangoItem</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">架构概览</a></li>
<li class="toctree-l1"><a class="reference internal" href="downloader-middleware.html">下载器中间件(Downloader Middleware)</a></li>
<li class="toctree-l1"><a class="reference internal" href="spider-middleware.html">Spider中间件(Middleware)</a></li>
<li class="toctree-l1"><a class="reference internal" href="extensions.html">扩展(Extensions)</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">核心API</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="request-response.html">Requests and Responses</a></li>
<li class="toctree-l1"><a class="reference internal" href="settings.html">Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="signals.html">信号(Signals)</a></li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">异常(Exceptions)</a></li>
<li class="toctree-l1"><a class="reference internal" href="exporters.html">Item Exporters</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Release notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to Scrapy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../versioning.html">Versioning and API Stability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../experimental/index.html">试验阶段特性</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index-2.html">Scrapy 中文手册</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          





<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index-2.html"> &mdash; Scrapy 中文手册 0.25 文档</a> &raquo;</li>
      
    <li>Spiders</li>
      <li class="wy-breadcrumbs-aside">
        
            <a href="../../../index.html" class="fa fa-github"> 在线手册中心</a>
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
    
  <div class="section" id="spiders">
<span id="topics-spiders"></span><h1>Spiders<a class="headerlink" href="#spiders" title="永久链接至标题">¶</a></h1>
<p>Spider类定义了如何爬取某个(或某些)网站。包括了爬取的动作(例如:是否跟进链接)以及如何从网页的内容中提取结构化数据(爬取item)。
换句话说，Spider就是您定义爬取的动作及分析某个网页(或者是有些网页)的地方。</p>
<p>对spider来说，爬取的循环类似下文:</p>
<ol class="arabic">
<li><p class="first">以初始的URL初始化Request，并设置回调函数。
当该request下载完毕并返回时，将生成response，并作为参数传给该回调函数。</p>
<p>spider中初始的request是通过调用 <a class="reference internal" href="#scrapy.spider.Spider.start_requests" title="scrapy.spider.Spider.start_requests"><code class="xref py py-meth docutils literal"><span class="pre">start_requests()</span></code></a> 来获取的。
<a class="reference internal" href="#scrapy.spider.Spider.start_requests" title="scrapy.spider.Spider.start_requests"><code class="xref py py-meth docutils literal"><span class="pre">start_requests()</span></code></a> 读取 <a class="reference internal" href="#scrapy.spider.Spider.start_urls" title="scrapy.spider.Spider.start_urls"><code class="xref py py-attr docutils literal"><span class="pre">start_urls</span></code></a> 中的URL，
并以 <a class="reference internal" href="#scrapy.spider.Spider.parse" title="scrapy.spider.Spider.parse"><code class="xref py py-attr docutils literal"><span class="pre">parse</span></code></a> 为回调函数生成 <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal"><span class="pre">Request</span></code></a> 。</p>
</li>
<li><p class="first">在回调函数内分析返回的(网页)内容，返回 <a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><code class="xref py py-class docutils literal"><span class="pre">Item</span></code></a> 对象或者 <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal"><span class="pre">Request</span></code></a> 或者一个包括二者的可迭代容器。
返回的Request对象之后会经过Scrapy处理，下载相应的内容，并调用设置的callback函数(函数可相同)。</p>
</li>
<li><p class="first">在回调函数内，您可以使用 <a class="reference internal" href="selectors.html#topics-selectors"><span>选择器(Selectors)</span></a>
(您也可以使用BeautifulSoup, lxml 或者您想用的任何解析器) 来分析网页内容，并根据分析的数据生成item。</p>
</li>
<li><p class="first">最后，由spider返回的item将被存到数据库(由某些
<a class="reference internal" href="item-pipeline.html#topics-item-pipeline"><span>Item Pipeline</span></a> 处理)或使用
<a class="reference internal" href="feed-exports.html#topics-feed-exports"><span>Feed exports</span></a> 存入到文件中。</p>
</li>
</ol>
<p>虽然该循环对任何类型的spider都(多少)适用，但Scrapy仍然为了不同的需求提供了多种默认spider。
之后将讨论这些spider。</p>
<div class="section" id="spider">
<span id="spiderargs"></span><h2>Spider参数<a class="headerlink" href="#spider" title="永久链接至标题">¶</a></h2>
<p>Spider可以通过接受参数来修改其功能。
spider参数一般用来定义初始URL或者指定限制爬取网站的部分。
您也可以使用其来配置spider的任何功能。</p>
<p>在运行 <strong class="command">crawl</strong> 时添加 <code class="docutils literal"><span class="pre">-a</span></code> 可以传递Spider参数:</p>
<div class="highlight-python"><div class="highlight"><pre>scrapy crawl myspider -a category=electronics
</pre></div>
</div>
<p>Spider在构造器(constructor)中获取参数:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">&#39;myspider&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MySpider</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.example.com/categories/</span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span> <span class="n">category</span><span class="p">]</span>
        <span class="c"># ...</span>
</pre></div>
</div>
<p>Spider参数也可以通过Scrapyd的 <code class="docutils literal"><span class="pre">schedule.json</span></code> API来传递。
参见 <a class="reference external" href="http://scrapyd.readthedocs.org/">Scrapyd documentation</a>.</p>
</div>
<div class="section" id="topics-spiders-ref">
<span id="id1"></span><h2>内置Spider参考手册<a class="headerlink" href="#topics-spiders-ref" title="永久链接至标题">¶</a></h2>
<p>Scrapy提供多种方便的通用spider供您继承使用。
这些spider为一些常用的爬取情况提供方便的特性，
例如根据某些规则跟进某个网站的所有链接、根据 <a class="reference external" href="http://www.sitemaps.org/">Sitemaps</a> 来进行爬取，或者分析XML/CSV源。</p>
<p>下面spider的示例中，我们假定您有个项目在 <code class="docutils literal"><span class="pre">myproject.items</span></code> 模块中声明了 <code class="docutils literal"><span class="pre">TestItem</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">TestItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
    <span class="nb">id</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">description</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
</pre></div>
</div>
<span class="target" id="module-scrapy.spider"></span><div class="section" id="id2">
<h3>Spider<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.spider.Spider">
<em class="property">class </em><code class="descclassname">scrapy.spider.</code><code class="descname">Spider</code><a class="headerlink" href="#scrapy.spider.Spider" title="永久链接至目标">¶</a></dt>
<dd><p>Spider是最简单的spider。每个其他的spider必须继承自该类(包括Scrapy自带的其他spider以及您自己编写的spider)。
Spider并没有提供什么特殊的功能。
其仅仅请求给定的 <code class="docutils literal"><span class="pre">start_urls</span></code>/<code class="docutils literal"><span class="pre">start_requests</span></code> ，并根据返回的结果(resulting responses)调用spider的 <code class="docutils literal"><span class="pre">parse</span></code> 方法。</p>
<dl class="attribute">
<dt id="scrapy.spider.Spider.name">
<code class="descname">name</code><a class="headerlink" href="#scrapy.spider.Spider.name" title="永久链接至目标">¶</a></dt>
<dd><p>定义spider名字的字符串(string)。spider的名字定义了Scrapy如何定位(并初始化)spider，所以其必须是唯一的。
不过您可以生成多个相同的spider实例(instance)，这没有任何限制。
name是spider最重要的属性，而且是必须的。</p>
<p>如果该spider爬取单个网站(single domain)，一个常见的做法是以该网站(domain)(加或不加 <a class="reference external" href="http://en.wikipedia.org/wiki/Top-level_domain">后缀</a> )来命名spider。
例如，如果spider爬取 <code class="docutils literal"><span class="pre">mywebsite.com</span></code> ，该spider通常会被命名为 <code class="docutils literal"><span class="pre">mywebsite</span></code> 。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.spider.Spider.allowed_domains">
<code class="descname">allowed_domains</code><a class="headerlink" href="#scrapy.spider.Spider.allowed_domains" title="永久链接至目标">¶</a></dt>
<dd><p>可选。包含了spider允许爬取的域名(domain)列表(list)。
当 <a class="reference internal" href="spider-middleware.html#scrapy.contrib.spidermiddleware.offsite.OffsiteMiddleware" title="scrapy.contrib.spidermiddleware.offsite.OffsiteMiddleware"><code class="xref py py-class docutils literal"><span class="pre">OffsiteMiddleware</span></code></a> 启用时，
域名不在列表中的URL不会被跟进。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.spider.Spider.start_urls">
<code class="descname">start_urls</code><a class="headerlink" href="#scrapy.spider.Spider.start_urls" title="永久链接至目标">¶</a></dt>
<dd><p>URL列表。当没有制定特定的URL时，spider将从该列表中开始进行爬取。
因此，第一个被获取到的页面的URL将是该列表之一。
后续的URL将会从获取到的数据中提取。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.spider.Spider.crawler">
<code class="descname">crawler</code><a class="headerlink" href="#scrapy.spider.Spider.crawler" title="永久链接至目标">¶</a></dt>
<dd><p>This attribute is set by the <a class="reference internal" href="#scrapy.spider.Spider.from_crawler" title="scrapy.spider.Spider.from_crawler"><code class="xref py py-meth docutils literal"><span class="pre">from_crawler()</span></code></a> class method after
initializating the class, and links to the
<a class="reference internal" href="api.html#scrapy.crawler.Crawler" title="scrapy.crawler.Crawler"><code class="xref py py-class docutils literal"><span class="pre">Crawler</span></code></a> object to which this spider instance is
bound.</p>
<p>Crawlers encapsulate a lot of components in the project for their single
entry access (such as extensions, middlewares, signals managers, etc).
See <a class="reference internal" href="api.html#topics-api-crawler"><span>Crawler API</span></a> to know more about them.</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.spider.Spider.settings">
<code class="descname">settings</code><a class="headerlink" href="#scrapy.spider.Spider.settings" title="永久链接至目标">¶</a></dt>
<dd><p>Configuration on which this spider is been ran. This is a
<a class="reference internal" href="api.html#scrapy.settings.Settings" title="scrapy.settings.Settings"><code class="xref py py-class docutils literal"><span class="pre">Settings</span></code></a> instance, see the
<a class="reference internal" href="settings.html#topics-settings"><span>Settings</span></a> topic for a detailed introduction on this subject.</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.spider.Spider.from_crawler">
<code class="descname">from_crawler</code><span class="sig-paren">(</span><em>crawler</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spider.Spider.from_crawler" title="永久链接至目标">¶</a></dt>
<dd><p>This is the class method used by Scrapy to create your spiders.</p>
<p>You probably won&#8217;t need to override this directly, since the default
implementation acts as a proxy to the <code class="xref py py-meth docutils literal"><span class="pre">__init__()</span></code> method, calling
it with the given arguments <cite>args</cite> and named arguments <cite>kwargs</cite>.</p>
<p>Nonetheless, this method sets the <a class="reference internal" href="#scrapy.spider.Spider.crawler" title="scrapy.spider.Spider.crawler"><code class="xref py py-attr docutils literal"><span class="pre">crawler</span></code></a> and <a class="reference internal" href="#scrapy.spider.Spider.settings" title="scrapy.spider.Spider.settings"><code class="xref py py-attr docutils literal"><span class="pre">settings</span></code></a>
attributes in the new instance, so they can be accessed later inside the
spider&#8217;s code.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><ul class="first last simple">
<li><strong>crawler</strong> (<a class="reference internal" href="api.html#scrapy.crawler.Crawler" title="scrapy.crawler.Crawler"><code class="xref py py-class docutils literal"><span class="pre">Crawler</span></code></a> instance) &#8211; crawler to which the spider will be bound</li>
<li><strong>args</strong> (<a class="reference internal" href="api.html#scrapy.spidermanager.SpiderManager.list" title="scrapy.spidermanager.SpiderManager.list"><em>list</em></a>) &#8211; arguments passed to the <code class="xref py py-meth docutils literal"><span class="pre">__init__()</span></code> method</li>
<li><strong>kwargs</strong> (<em>dict</em>) &#8211; keyword arguments passed to the <code class="xref py py-meth docutils literal"><span class="pre">__init__()</span></code> method</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.spider.Spider.start_requests">
<code class="descname">start_requests</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spider.Spider.start_requests" title="永久链接至目标">¶</a></dt>
<dd><p>该方法必须返回一个可迭代对象(iterable)。该对象包含了spider用于爬取的第一个Request。</p>
<p>当spider启动爬取并且未制定URL时，该方法被调用。
当指定了URL时，<a class="reference internal" href="#scrapy.spider.Spider.make_requests_from_url" title="scrapy.spider.Spider.make_requests_from_url"><code class="xref py py-meth docutils literal"><span class="pre">make_requests_from_url()</span></code></a> 将被调用来创建Request对象。
该方法仅仅会被Scrapy调用一次，因此您可以将其实现为生成器。</p>
<p>该方法的默认实现是使用 <a class="reference internal" href="#scrapy.spider.Spider.start_urls" title="scrapy.spider.Spider.start_urls"><code class="xref py py-attr docutils literal"><span class="pre">start_urls</span></code></a> 的url生成Request。</p>
<p>如果您想要修改最初爬取某个网站的Request对象，您可以重写(override)该方法。
例如，如果您需要在启动时以POST登录某个网站，你可以这么写:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">FormRequest</span><span class="p">(</span><span class="s">&quot;http://www.example.com/login&quot;</span><span class="p">,</span>
                               <span class="n">formdata</span><span class="o">=</span><span class="p">{</span><span class="s">&#39;user&#39;</span><span class="p">:</span> <span class="s">&#39;john&#39;</span><span class="p">,</span> <span class="s">&#39;pass&#39;</span><span class="p">:</span> <span class="s">&#39;secret&#39;</span><span class="p">},</span>
                               <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">logged_in</span><span class="p">)]</span>

<span class="k">def</span> <span class="nf">logged_in</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
    <span class="c"># here you would extract links to follow and return Requests for</span>
    <span class="c"># each of them, with another callback</span>
    <span class="k">pass</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="scrapy.spider.Spider.make_requests_from_url">
<code class="descname">make_requests_from_url</code><span class="sig-paren">(</span><em>url</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spider.Spider.make_requests_from_url" title="永久链接至目标">¶</a></dt>
<dd><p>该方法接受一个URL并返回用于爬取的 <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal"><span class="pre">Request</span></code></a> 对象。
该方法在初始化request时被 <a class="reference internal" href="#scrapy.spider.Spider.start_requests" title="scrapy.spider.Spider.start_requests"><code class="xref py py-meth docutils literal"><span class="pre">start_requests()</span></code></a> 调用，也被用于转化url为request。</p>
<p>默认未被复写(overridden)的情况下，该方法返回的Request对象中，
<a class="reference internal" href="#scrapy.spider.Spider.parse" title="scrapy.spider.Spider.parse"><code class="xref py py-meth docutils literal"><span class="pre">parse()</span></code></a> 作为回调函数，dont_filter参数也被设置为开启。
(详情参见 <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal"><span class="pre">Request</span></code></a>).</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.spider.Spider.parse">
<code class="descname">parse</code><span class="sig-paren">(</span><em>response</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spider.Spider.parse" title="永久链接至目标">¶</a></dt>
<dd><p>当response没有指定回调函数时，该方法是Scrapy处理下载的response的默认方法。</p>
<p><code class="docutils literal"><span class="pre">parse</span></code> 负责处理response并返回处理的数据以及(/或)跟进的URL。
<a class="reference internal" href="#scrapy.spider.Spider" title="scrapy.spider.Spider"><code class="xref py py-class docutils literal"><span class="pre">Spider</span></code></a> 对其他的Request的回调函数也有相同的要求。</p>
<p>该方法及其他的Request回调函数必须返回一个包含
<a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal"><span class="pre">Request</span></code></a> 及(或) <a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><code class="xref py py-class docutils literal"><span class="pre">Item</span></code></a>
的可迭代的对象。</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><strong>response</strong> (<a class="reference internal" href="request-response.html#scrapy.http.Response" title="scrapy.http.Response"><code class="xref py py-class docutils literal"><span class="pre">Response</span></code></a>) &#8211; 用于分析的response</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.spider.Spider.log">
<code class="descname">log</code><span class="sig-paren">(</span><em>message</em><span class="optional">[</span>, <em>level</em>, <em>component</em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spider.Spider.log" title="永久链接至目标">¶</a></dt>
<dd><p>使用 <a class="reference internal" href="logging.html#scrapy.log.msg" title="scrapy.log.msg"><code class="xref py py-func docutils literal"><span class="pre">scrapy.log.msg()</span></code></a> 方法记录(log)message。
log中自动带上该spider的 <a class="reference internal" href="#scrapy.spider.Spider.name" title="scrapy.spider.Spider.name"><code class="xref py py-attr docutils literal"><span class="pre">name</span></code></a> 属性。
更多数据请参见 <a class="reference internal" href="logging.html#topics-logging"><span>Logging</span></a> 。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.spider.Spider.closed">
<code class="descname">closed</code><span class="sig-paren">(</span><em>reason</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spider.Spider.closed" title="永久链接至目标">¶</a></dt>
<dd><p>当spider关闭时，该函数被调用。
该方法提供了一个替代调用signals.connect()来监听 <a href="#id3"><span class="problematic" id="id4">:signal:`spider_closed`</span></a> 信号的快捷方式。</p>
</dd></dl>

</dd></dl>

<div class="section" id="id5">
<h4>Spider样例<a class="headerlink" href="#id5" title="永久链接至标题">¶</a></h4>
<p>让我们来看一个例子:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">&#39;example.com&#39;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;example.com&#39;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s">&#39;http://www.example.com/1.html&#39;</span><span class="p">,</span>
        <span class="s">&#39;http://www.example.com/2.html&#39;</span><span class="p">,</span>
        <span class="s">&#39;http://www.example.com/3.html&#39;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s">&#39;A response from </span><span class="si">%s</span><span class="s"> just arrived!&#39;</span> <span class="o">%</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">)</span>
</pre></div>
</div>
<p>另一个在单个回调函数中返回多个Request以及Item的例子:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">from</span> <span class="nn">myproject.items</span> <span class="kn">import</span> <span class="n">MyItem</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">&#39;example.com&#39;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;example.com&#39;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s">&#39;http://www.example.com/1.html&#39;</span><span class="p">,</span>
        <span class="s">&#39;http://www.example.com/2.html&#39;</span><span class="p">,</span>
        <span class="s">&#39;http://www.example.com/3.html&#39;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">sel</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Selector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">h3</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;//h3&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">():</span>
            <span class="k">yield</span> <span class="n">MyItem</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">h3</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;//a/@href&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">():</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</pre></div>
</div>
<span class="target" id="module-scrapy.contrib.spiders"></span></div>
</div>
<div class="section" id="crawlspider">
<h3>CrawlSpider<a class="headerlink" href="#crawlspider" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.spiders.CrawlSpider">
<em class="property">class </em><code class="descclassname">scrapy.contrib.spiders.</code><code class="descname">CrawlSpider</code><a class="headerlink" href="#scrapy.contrib.spiders.CrawlSpider" title="永久链接至目标">¶</a></dt>
<dd><p>爬取一般网站常用的spider。其定义了一些规则(rule)来提供跟进link的方便的机制。
也许该spider并不是完全适合您的特定网站或项目，但其对很多情况都使用。
因此您可以以其为起点，根据需求修改部分方法。当然您也可以实现自己的spider。</p>
<p>除了从Spider继承过来的(您必须提供的)属性外，其提供了一个新的属性:</p>
<dl class="attribute">
<dt id="scrapy.contrib.spiders.CrawlSpider.rules">
<code class="descname">rules</code><a class="headerlink" href="#scrapy.contrib.spiders.CrawlSpider.rules" title="永久链接至目标">¶</a></dt>
<dd><p>一个包含一个(或多个) <a class="reference internal" href="#scrapy.contrib.spiders.Rule" title="scrapy.contrib.spiders.Rule"><code class="xref py py-class docutils literal"><span class="pre">Rule</span></code></a> 对象的集合(list)。
每个 <a class="reference internal" href="#scrapy.contrib.spiders.Rule" title="scrapy.contrib.spiders.Rule"><code class="xref py py-class docutils literal"><span class="pre">Rule</span></code></a> 对爬取网站的动作定义了特定表现。
Rule对象在下边会介绍。
如果多个rule匹配了相同的链接，则根据他们在本属性中被定义的顺序，第一个会被使用。</p>
</dd></dl>

<p>该spider也提供了一个可复写(overrideable)的方法:</p>
<dl class="method">
<dt id="scrapy.contrib.spiders.CrawlSpider.parse_start_url">
<code class="descname">parse_start_url</code><span class="sig-paren">(</span><em>response</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.contrib.spiders.CrawlSpider.parse_start_url" title="永久链接至目标">¶</a></dt>
<dd><p>当start_url的请求返回时，该方法被调用。
该方法分析最初的返回值并必须返回一个
<a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><code class="xref py py-class docutils literal"><span class="pre">Item</span></code></a> 对象或者
一个 <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal"><span class="pre">Request</span></code></a> 对象或者
一个可迭代的包含二者对象。</p>
</dd></dl>

</dd></dl>

<div class="section" id="crawling-rules">
<h4>爬取规则(Crawling rules)<a class="headerlink" href="#crawling-rules" title="永久链接至标题">¶</a></h4>
<dl class="class">
<dt id="scrapy.contrib.spiders.Rule">
<em class="property">class </em><code class="descclassname">scrapy.contrib.spiders.</code><code class="descname">Rule</code><span class="sig-paren">(</span><em>link_extractor</em>, <em>callback=None</em>, <em>cb_kwargs=None</em>, <em>follow=None</em>, <em>process_links=None</em>, <em>process_request=None</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.contrib.spiders.Rule" title="永久链接至目标">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">link_extractor</span></code> 是一个 <a class="reference internal" href="link-extractors.html#topics-link-extractors"><span>Link Extractor</span></a> 对象。
其定义了如何从爬取到的页面提取链接。</p>
<p><code class="docutils literal"><span class="pre">callback</span></code> 是一个callable或string(该spider中同名的函数将会被调用)。
从link_extractor中每获取到链接时将会调用该函数。该回调函数接受一个response作为其第一个参数，
并返回一个包含 <a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><code class="xref py py-class docutils literal"><span class="pre">Item</span></code></a> 以及(或) <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal"><span class="pre">Request</span></code></a> 对象(或者这两者的子类)的列表(list)。</p>
<div class="admonition warning">
<p class="first admonition-title">警告</p>
<p class="last">当编写爬虫规则时，请避免使用 <code class="docutils literal"><span class="pre">parse</span></code> 作为回调函数。
由于 <a class="reference internal" href="#scrapy.contrib.spiders.CrawlSpider" title="scrapy.contrib.spiders.CrawlSpider"><code class="xref py py-class docutils literal"><span class="pre">CrawlSpider</span></code></a> 使用 <code class="docutils literal"><span class="pre">parse</span></code> 方法来实现其逻辑，如果
您覆盖了 <code class="docutils literal"><span class="pre">parse</span></code> 方法，crawl spider 将会运行失败。</p>
</div>
<p><code class="docutils literal"><span class="pre">cb_kwargs</span></code> 包含传递给回调函数的参数(keyword argument)的字典。</p>
<p><code class="docutils literal"><span class="pre">follow</span></code> 是一个布尔(boolean)值，指定了根据该规则从response提取的链接是否需要跟进。
如果 <code class="docutils literal"><span class="pre">callback</span></code> 为None， <code class="docutils literal"><span class="pre">follow</span></code> 默认设置为 <code class="docutils literal"><span class="pre">True</span></code> ，否则默认为 <code class="docutils literal"><span class="pre">False</span></code> 。</p>
<p><code class="docutils literal"><span class="pre">process_links</span></code> 是一个callable或string(该spider中同名的函数将会被调用)。
从link_extractor中获取到链接列表时将会调用该函数。该方法主要用来过滤。</p>
<p><code class="docutils literal"><span class="pre">process_request</span></code> 是一个callable或string(该spider中同名的函数将会被调用)。
该规则提取到每个request时都会调用该函数。该函数必须返回一个request或者None。
(用来过滤request)</p>
</dd></dl>

</div>
<div class="section" id="id6">
<h4>CrawlSpider样例<a class="headerlink" href="#id6" title="永久链接至标题">¶</a></h4>
<p>接下来给出配合rule使用CrawlSpider的例子:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">CrawlSpider</span><span class="p">,</span> <span class="n">Rule</span>
<span class="kn">from</span> <span class="nn">scrapy.contrib.linkextractors</span> <span class="kn">import</span> <span class="n">LinkExtractor</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">CrawlSpider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">&#39;example.com&#39;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;example.com&#39;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.example.com&#39;</span><span class="p">]</span>

    <span class="n">rules</span> <span class="o">=</span> <span class="p">(</span>
        <span class="c"># 提取匹配 &#39;category.php&#39; (但不匹配 &#39;subsection.php&#39;) 的链接并跟进链接(没有callback意味着follow默认为True)</span>
        <span class="n">Rule</span><span class="p">(</span><span class="n">LinkExtractor</span><span class="p">(</span><span class="n">allow</span><span class="o">=</span><span class="p">(</span><span class="s">&#39;category\.php&#39;</span><span class="p">,</span> <span class="p">),</span> <span class="n">deny</span><span class="o">=</span><span class="p">(</span><span class="s">&#39;subsection\.php&#39;</span><span class="p">,</span> <span class="p">))),</span>

        <span class="c"># 提取匹配 &#39;item.php&#39; 的链接并使用spider的parse_item方法进行分析</span>
        <span class="n">Rule</span><span class="p">(</span><span class="n">LinkExtractor</span><span class="p">(</span><span class="n">allow</span><span class="o">=</span><span class="p">(</span><span class="s">&#39;item\.php&#39;</span><span class="p">,</span> <span class="p">)),</span> <span class="n">callback</span><span class="o">=</span><span class="s">&#39;parse_item&#39;</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s">&#39;Hi, this is an item page! </span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">)</span>

        <span class="n">item</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s">&#39;id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;//td[@id=&quot;item_id&quot;]/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">re</span><span class="p">(</span><span class="s">r&#39;ID: (\d+)&#39;</span><span class="p">)</span>
        <span class="n">item</span><span class="p">[</span><span class="s">&#39;name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;//td[@id=&quot;item_name&quot;]/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s">&#39;description&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;//td[@id=&quot;item_description&quot;]/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">item</span>
</pre></div>
</div>
<p>该spider将从example.com的首页开始爬取，获取category以及item的链接并对后者使用 <code class="docutils literal"><span class="pre">parse_item</span></code> 方法。
当item获得返回(response)时，将使用XPath处理HTML并生成一些数据填入 <a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><code class="xref py py-class docutils literal"><span class="pre">Item</span></code></a> 中。</p>
</div>
</div>
<div class="section" id="xmlfeedspider">
<h3>XMLFeedSpider<a class="headerlink" href="#xmlfeedspider" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.spiders.XMLFeedSpider">
<em class="property">class </em><code class="descclassname">scrapy.contrib.spiders.</code><code class="descname">XMLFeedSpider</code><a class="headerlink" href="#scrapy.contrib.spiders.XMLFeedSpider" title="永久链接至目标">¶</a></dt>
<dd><p>XMLFeedSpider被设计用于通过迭代各个节点来分析XML源(XML feed)。
迭代器可以从 <code class="docutils literal"><span class="pre">iternodes</span></code> ， <code class="docutils literal"><span class="pre">xml</span></code> ， <code class="docutils literal"><span class="pre">html</span></code> 选择。
鉴于 <code class="docutils literal"><span class="pre">xml</span></code> 以及 <code class="docutils literal"><span class="pre">html</span></code> 迭代器需要先读取所有DOM再分析而引起的性能问题，
一般还是推荐使用 <code class="docutils literal"><span class="pre">iternodes</span></code> 。
不过使用 <code class="docutils literal"><span class="pre">html</span></code> 作为迭代器能有效应对错误的XML。</p>
<p>您必须定义下列类属性来设置迭代器以及标签名(tag name):</p>
<dl class="attribute">
<dt id="scrapy.contrib.spiders.XMLFeedSpider.iterator">
<code class="descname">iterator</code><a class="headerlink" href="#scrapy.contrib.spiders.XMLFeedSpider.iterator" title="永久链接至目标">¶</a></dt>
<dd><p>用于确定使用哪个迭代器的string。可选项有:</p>
<blockquote>
<div><ul class="simple">
<li><code class="docutils literal"><span class="pre">'iternodes'</span></code> - 一个高性能的基于正则表达式的迭代器</li>
<li><code class="docutils literal"><span class="pre">'html'</span></code> - 使用 <a class="reference internal" href="selectors.html#scrapy.selector.Selector" title="scrapy.selector.Selector"><code class="xref py py-class docutils literal"><span class="pre">Selector</span></code></a> 的迭代器。
需要注意的是该迭代器使用DOM进行分析，其需要将所有的DOM载入内存，
当数据量大的时候会产生问题。</li>
<li><code class="docutils literal"><span class="pre">'xml'</span></code> - 使用 <a class="reference internal" href="selectors.html#scrapy.selector.Selector" title="scrapy.selector.Selector"><code class="xref py py-class docutils literal"><span class="pre">Selector</span></code></a> 的迭代器。
需要注意的是该迭代器使用DOM进行分析，其需要将所有的DOM载入内存，
当数据量大的时候会产生问题。</li>
</ul>
</div></blockquote>
<p>默认值为 <code class="docutils literal"><span class="pre">iternodes</span></code> 。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.contrib.spiders.XMLFeedSpider.itertag">
<code class="descname">itertag</code><a class="headerlink" href="#scrapy.contrib.spiders.XMLFeedSpider.itertag" title="永久链接至目标">¶</a></dt>
<dd><p>一个包含开始迭代的节点名的string。例如:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">itertag</span> <span class="o">=</span> <span class="s">&#39;product&#39;</span>
</pre></div>
</div>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.contrib.spiders.XMLFeedSpider.namespaces">
<code class="descname">namespaces</code><a class="headerlink" href="#scrapy.contrib.spiders.XMLFeedSpider.namespaces" title="永久链接至目标">¶</a></dt>
<dd><p>一个由 <code class="docutils literal"><span class="pre">(prefix,</span> <span class="pre">url)</span></code> 元组(tuple)所组成的list。
其定义了在该文档中会被spider处理的可用的namespace。
<code class="docutils literal"><span class="pre">prefix</span></code> 及 <code class="docutils literal"><span class="pre">uri</span></code> 会被自动调用
<a class="reference internal" href="selectors.html#scrapy.selector.Selector.register_namespace" title="scrapy.selector.Selector.register_namespace"><code class="xref py py-meth docutils literal"><span class="pre">register_namespace()</span></code></a> 生成namespace。</p>
<p>您可以通过在 <a class="reference internal" href="#scrapy.contrib.spiders.XMLFeedSpider.itertag" title="scrapy.contrib.spiders.XMLFeedSpider.itertag"><code class="xref py py-attr docutils literal"><span class="pre">itertag</span></code></a> 属性中制定节点的namespace。</p>
<p>例如:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">class</span> <span class="nc">YourSpider</span><span class="p">(</span><span class="n">XMLFeedSpider</span><span class="p">):</span>

    <span class="n">namespaces</span> <span class="o">=</span> <span class="p">[(</span><span class="s">&#39;n&#39;</span><span class="p">,</span> <span class="s">&#39;http://www.sitemaps.org/schemas/sitemap/0.9&#39;</span><span class="p">)]</span>
    <span class="n">itertag</span> <span class="o">=</span> <span class="s">&#39;n:url&#39;</span>
    <span class="c"># ...</span>
</pre></div>
</div>
</dd></dl>

<p>除了这些新的属性之外，该spider也有以下可以覆盖(overrideable)的方法:</p>
<dl class="method">
<dt id="scrapy.contrib.spiders.XMLFeedSpider.adapt_response">
<code class="descname">adapt_response</code><span class="sig-paren">(</span><em>response</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.contrib.spiders.XMLFeedSpider.adapt_response" title="永久链接至目标">¶</a></dt>
<dd><p>该方法在spider分析response前被调用。您可以在response被分析之前使用该函数来修改内容(body)。
该方法接受一个response并返回一个response(可以相同也可以不同)。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.contrib.spiders.XMLFeedSpider.parse_node">
<code class="descname">parse_node</code><span class="sig-paren">(</span><em>response</em>, <em>selector</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.contrib.spiders.XMLFeedSpider.parse_node" title="永久链接至目标">¶</a></dt>
<dd><p>当节点符合提供的标签名时(<code class="docutils literal"><span class="pre">itertag</span></code>)该方法被调用。
接收到的response以及相应的 <a class="reference internal" href="selectors.html#scrapy.selector.Selector" title="scrapy.selector.Selector"><code class="xref py py-class docutils literal"><span class="pre">Selector</span></code></a> 作为参数传递给该方法。
该方法返回一个 <a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><code class="xref py py-class docutils literal"><span class="pre">Item</span></code></a> 对象或者
<a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal"><span class="pre">Request</span></code></a> 对象 或者一个包含二者的可迭代对象(iterable)。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.contrib.spiders.XMLFeedSpider.process_results">
<code class="descname">process_results</code><span class="sig-paren">(</span><em>response</em>, <em>results</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.contrib.spiders.XMLFeedSpider.process_results" title="永久链接至目标">¶</a></dt>
<dd><p>当spider返回结果(item或request)时该方法被调用。
设定该方法的目的是在结果返回给框架核心(framework core)之前做最后的处理，
例如设定item的ID。其接受一个结果的列表(list of results)及对应的response。
其结果必须返回一个结果的列表(list of results)(包含Item或者Request对象)。</p>
</dd></dl>

</dd></dl>

<div class="section" id="id7">
<h4>XMLFeedSpider例子<a class="headerlink" href="#id7" title="永久链接至标题">¶</a></h4>
<p>该spider十分易用。下边是其中一个例子:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy</span> <span class="kn">import</span> <span class="n">log</span>
<span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">XMLFeedSpider</span>
<span class="kn">from</span> <span class="nn">myproject.items</span> <span class="kn">import</span> <span class="n">TestItem</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">XMLFeedSpider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">&#39;example.com&#39;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;example.com&#39;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.example.com/feed.xml&#39;</span><span class="p">]</span>
    <span class="n">iterator</span> <span class="o">=</span> <span class="s">&#39;iternodes&#39;</span> <span class="c"># This is actually unnecessary, since it&#39;s the default value</span>
    <span class="n">itertag</span> <span class="o">=</span> <span class="s">&#39;item&#39;</span>

    <span class="k">def</span> <span class="nf">parse_node</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">,</span> <span class="n">node</span><span class="p">):</span>
        <span class="n">log</span><span class="o">.</span><span class="n">msg</span><span class="p">(</span><span class="s">&#39;Hi, this is a &lt;</span><span class="si">%s</span><span class="s">&gt; node!: </span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">itertag</span><span class="p">,</span> <span class="s">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">extract</span><span class="p">())))</span>

        <span class="n">item</span> <span class="o">=</span> <span class="n">TestItem</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s">&#39;id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;@id&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s">&#39;name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;name&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s">&#39;description&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;description&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">item</span>
</pre></div>
</div>
<p>简单来说，我们在这里创建了一个spider，从给定的 <code class="docutils literal"><span class="pre">start_urls</span></code> 中下载feed，
并迭代feed中每个 <code class="docutils literal"><span class="pre">item</span></code> 标签，输出，并在 <a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><code class="xref py py-class docutils literal"><span class="pre">Item</span></code></a> 中存储有些随机数据。</p>
</div>
</div>
<div class="section" id="csvfeedspider">
<h3>CSVFeedSpider<a class="headerlink" href="#csvfeedspider" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.spiders.CSVFeedSpider">
<em class="property">class </em><code class="descclassname">scrapy.contrib.spiders.</code><code class="descname">CSVFeedSpider</code><a class="headerlink" href="#scrapy.contrib.spiders.CSVFeedSpider" title="永久链接至目标">¶</a></dt>
<dd><p>该spider除了其按行遍历而不是节点之外其他和XMLFeedSpider十分类似。
而其在每次迭代时调用的是 <a class="reference internal" href="#scrapy.contrib.spiders.CSVFeedSpider.parse_row" title="scrapy.contrib.spiders.CSVFeedSpider.parse_row"><code class="xref py py-meth docutils literal"><span class="pre">parse_row()</span></code></a> 。</p>
<dl class="attribute">
<dt id="scrapy.contrib.spiders.CSVFeedSpider.delimiter">
<code class="descname">delimiter</code><a class="headerlink" href="#scrapy.contrib.spiders.CSVFeedSpider.delimiter" title="永久链接至目标">¶</a></dt>
<dd><p>在CSV文件中用于区分字段的分隔符。类型为string。
默认为 <code class="docutils literal"><span class="pre">','</span></code> (逗号)。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.contrib.spiders.CSVFeedSpider.headers">
<code class="descname">headers</code><a class="headerlink" href="#scrapy.contrib.spiders.CSVFeedSpider.headers" title="永久链接至目标">¶</a></dt>
<dd><p>在CSV文件中包含的用来提取字段的行的列表。参考下边的例子。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.contrib.spiders.CSVFeedSpider.parse_row">
<code class="descname">parse_row</code><span class="sig-paren">(</span><em>response</em>, <em>row</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.contrib.spiders.CSVFeedSpider.parse_row" title="永久链接至目标">¶</a></dt>
<dd><p>该方法接收一个response对象及一个以提供或检测出来的header为键的字典(代表每行)。
该spider中，您也可以覆盖 <code class="docutils literal"><span class="pre">adapt_response</span></code> 及
<code class="docutils literal"><span class="pre">process_results</span></code> 方法来进行预处理(pre-processing)及后(post-processing)处理。</p>
</dd></dl>

</dd></dl>

<div class="section" id="id8">
<h4>CSVFeedSpider例子<a class="headerlink" href="#id8" title="永久链接至标题">¶</a></h4>
<p>下面的例子和之前的例子很像，但使用了
<a class="reference internal" href="#scrapy.contrib.spiders.CSVFeedSpider" title="scrapy.contrib.spiders.CSVFeedSpider"><code class="xref py py-class docutils literal"><span class="pre">CSVFeedSpider</span></code></a>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy</span> <span class="kn">import</span> <span class="n">log</span>
<span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">CSVFeedSpider</span>
<span class="kn">from</span> <span class="nn">myproject.items</span> <span class="kn">import</span> <span class="n">TestItem</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">CSVFeedSpider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">&#39;example.com&#39;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;example.com&#39;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.example.com/feed.csv&#39;</span><span class="p">]</span>
    <span class="n">delimiter</span> <span class="o">=</span> <span class="s">&#39;;&#39;</span>
    <span class="n">headers</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;id&#39;</span><span class="p">,</span> <span class="s">&#39;name&#39;</span><span class="p">,</span> <span class="s">&#39;description&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse_row</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">,</span> <span class="n">row</span><span class="p">):</span>
        <span class="n">log</span><span class="o">.</span><span class="n">msg</span><span class="p">(</span><span class="s">&#39;Hi, this is a row!: </span><span class="si">%r</span><span class="s">&#39;</span> <span class="o">%</span> <span class="n">row</span><span class="p">)</span>

        <span class="n">item</span> <span class="o">=</span> <span class="n">TestItem</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s">&#39;id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s">&#39;id&#39;</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s">&#39;name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s">&#39;name&#39;</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s">&#39;description&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s">&#39;description&#39;</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">item</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="sitemapspider">
<h3>SitemapSpider<a class="headerlink" href="#sitemapspider" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.spiders.SitemapSpider">
<em class="property">class </em><code class="descclassname">scrapy.contrib.spiders.</code><code class="descname">SitemapSpider</code><a class="headerlink" href="#scrapy.contrib.spiders.SitemapSpider" title="永久链接至目标">¶</a></dt>
<dd><p>SitemapSpider使您爬取网站时可以通过 <a class="reference external" href="http://www.sitemaps.org/">Sitemaps</a> 来发现爬取的URL。</p>
<p>其支持嵌套的sitemap，并能从 <a class="reference external" href="http://www.robotstxt.org/">robots.txt</a> 中获取sitemap的url。</p>
<dl class="attribute">
<dt id="scrapy.contrib.spiders.SitemapSpider.sitemap_urls">
<code class="descname">sitemap_urls</code><a class="headerlink" href="#scrapy.contrib.spiders.SitemapSpider.sitemap_urls" title="永久链接至目标">¶</a></dt>
<dd><p>包含您要爬取的url的sitemap的url列表(list)。
您也可以指定为一个 <a class="reference external" href="http://www.robotstxt.org/">robots.txt</a> ，spider会从中分析并提取url。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.contrib.spiders.SitemapSpider.sitemap_rules">
<code class="descname">sitemap_rules</code><a class="headerlink" href="#scrapy.contrib.spiders.SitemapSpider.sitemap_rules" title="永久链接至目标">¶</a></dt>
<dd><p>一个包含 <code class="docutils literal"><span class="pre">(regex,</span> <span class="pre">callback)</span></code> 元组的列表(list):</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">regex</span></code> 是一个用于匹配从sitemap提供的url的正则表达式。
<code class="docutils literal"><span class="pre">regex</span></code> 可以是一个字符串或者编译的正则对象(compiled regex object)。</li>
<li>callback指定了匹配正则表达式的url的处理函数。
<code class="docutils literal"><span class="pre">callback</span></code> 可以是一个字符串(spider中方法的名字)或者是callable。</li>
</ul>
<p>例如:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">sitemap_rules</span> <span class="o">=</span> <span class="p">[(</span><span class="s">&#39;/product/&#39;</span><span class="p">,</span> <span class="s">&#39;parse_product&#39;</span><span class="p">)]</span>
</pre></div>
</div>
<p>规则按顺序进行匹配，之后第一个匹配才会被应用。</p>
<p>如果您忽略该属性，sitemap中发现的所有url将会被 <code class="docutils literal"><span class="pre">parse</span></code> 函数处理。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.contrib.spiders.SitemapSpider.sitemap_follow">
<code class="descname">sitemap_follow</code><a class="headerlink" href="#scrapy.contrib.spiders.SitemapSpider.sitemap_follow" title="永久链接至目标">¶</a></dt>
<dd><p>一个用于匹配要跟进的sitemap的正则表达式的列表(list)。其仅仅被应用在
使用 <cite>Sitemap index files</cite> 来指向其他sitemap文件的站点。</p>
<p>默认情况下所有的sitemap都会被跟进。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.contrib.spiders.SitemapSpider.sitemap_alternate_links">
<code class="descname">sitemap_alternate_links</code><a class="headerlink" href="#scrapy.contrib.spiders.SitemapSpider.sitemap_alternate_links" title="永久链接至目标">¶</a></dt>
<dd><p>指定当一个 <code class="docutils literal"><span class="pre">url</span></code> 有可选的链接时，是否跟进。
有些非英文网站会在一个 <code class="docutils literal"><span class="pre">url</span></code> 块内提供其他语言的网站链接。</p>
<p>例如:</p>
<div class="highlight-python"><div class="highlight"><pre>&lt;url&gt;
    &lt;loc&gt;http://example.com/&lt;/loc&gt;
    &lt;xhtml:link rel=&quot;alternate&quot; hreflang=&quot;de&quot; href=&quot;http://example.com/de&quot;/&gt;
&lt;/url&gt;
</pre></div>
</div>
<p>当 <code class="docutils literal"><span class="pre">sitemap_alternate_links</span></code> 设置时，两个URL都会被获取。
当 <code class="docutils literal"><span class="pre">sitemap_alternate_links</span></code> 关闭时，只有 <code class="docutils literal"><span class="pre">http://example.com/</span></code> 会被获取。</p>
<p>默认 <code class="docutils literal"><span class="pre">sitemap_alternate_links</span></code> 关闭。</p>
</dd></dl>

</dd></dl>

<div class="section" id="id9">
<h4>SitemapSpider样例<a class="headerlink" href="#id9" title="永久链接至标题">¶</a></h4>
<p>简单的例子: 使用 <code class="docutils literal"><span class="pre">parse</span></code> 处理通过sitemap发现的所有url:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">SitemapSpider</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">SitemapSpider</span><span class="p">):</span>
    <span class="n">sitemap_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.example.com/sitemap.xml&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">pass</span> <span class="c"># ... scrape item here ...</span>
</pre></div>
</div>
<p>用特定的函数处理某些url，其他的使用另外的callback:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">SitemapSpider</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">SitemapSpider</span><span class="p">):</span>
    <span class="n">sitemap_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.example.com/sitemap.xml&#39;</span><span class="p">]</span>
    <span class="n">sitemap_rules</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s">&#39;/product/&#39;</span><span class="p">,</span> <span class="s">&#39;parse_product&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;/category/&#39;</span><span class="p">,</span> <span class="s">&#39;parse_category&#39;</span><span class="p">),</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse_product</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">pass</span> <span class="c"># ... scrape product ...</span>

    <span class="k">def</span> <span class="nf">parse_category</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">pass</span> <span class="c"># ... scrape category ...</span>
</pre></div>
</div>
<p>跟进 <a class="reference external" href="http://www.robotstxt.org/">robots.txt</a> 文件定义的sitemap并只跟进包含有 <code class="docutils literal"><span class="pre">..sitemap_shop</span></code> 的url:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">SitemapSpider</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">SitemapSpider</span><span class="p">):</span>
    <span class="n">sitemap_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.example.com/robots.txt&#39;</span><span class="p">]</span>
    <span class="n">sitemap_rules</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s">&#39;/shop/&#39;</span><span class="p">,</span> <span class="s">&#39;parse_shop&#39;</span><span class="p">),</span>
    <span class="p">]</span>
    <span class="n">sitemap_follow</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;/sitemap_shops&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse_shop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">pass</span> <span class="c"># ... scrape shop here ...</span>
</pre></div>
</div>
<p>在SitemapSpider中使用其他url:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">SitemapSpider</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">SitemapSpider</span><span class="p">):</span>
    <span class="n">sitemap_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.example.com/robots.txt&#39;</span><span class="p">]</span>
    <span class="n">sitemap_rules</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s">&#39;/shop/&#39;</span><span class="p">,</span> <span class="s">&#39;parse_shop&#39;</span><span class="p">),</span>
    <span class="p">]</span>

    <span class="n">other_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.example.com/about&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">requests</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">super</span><span class="p">(</span><span class="n">MySpider</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">start_requests</span><span class="p">())</span>
        <span class="n">requests</span> <span class="o">+=</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse_other</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">other_urls</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">requests</span>

    <span class="k">def</span> <span class="nf">parse_shop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">pass</span> <span class="c"># ... scrape shop here ...</span>

    <span class="k">def</span> <span class="nf">parse_other</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">pass</span> <span class="c"># ... scrape other here ...</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>


    

           </div>
          </div>
	<hr/>
	<div>
		<p>扫码关注，获取更多内容</p>
		<img src="../../../statics/img/qrcode.jpg" width="100" height="100" />
	</div>
	<!-- duoshuo start -->
	<div class="ds-thread"></div>
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"pytabdocs"};
		(function() {
			var ds = document.createElement('script');
			ds.type = 'text/javascript';ds.async = true;
			ds.src = '../../../statics/js/duoshuo.js';
			ds.charset = 'UTF-8';
			(document.getElementsByTagName('head')[0] 
			 || document.getElementsByTagName('body')[0]).appendChild(ds);
		})();
	</script>
	<!-- duoshuo end -->
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="selectors.html" class="btn btn-neutral float-right" title="选择器(Selectors)" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="items.html" class="btn btn-neutral" title="Items" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; 版权所有 Scrapy.

    </p>
  </div> 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.25',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="../_static/translations.js"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
  
     
    

  <script type="text/javascript" src="../../../static/js/global.html" ></script>
  <script type="text/javascript">
        var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
        document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3F141f4ed9eb11f462fa19fdd960639134' type='text/javascript'%3E%3C/script%3E"));
  </script>
</body>

<!-- Mirrored from docs.pythontab.com/scrapy/scrapy0.24/topics/spiders.html by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 04 Oct 2022 03:51:21 GMT -->
</html>